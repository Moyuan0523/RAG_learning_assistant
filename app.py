# åˆ©ç”¨ flask å°‡ python è®Šæˆç¶²é æ‡‰ç”¨çš„Webæ¡†æ¶
from flask import Flask, render_template, request, jsonify, current_app
from app.retriever import search_similar_chunks
from app.generator import generate_answer
#from langchain.memory import ConversationBufferMemory
from app.selfmake_memory import CustomMemory 
import pickle, os
import uuid

os.environ["TOKENIZERS_PARALLELISM"] = "false"

app = Flask(__name__)
#memory = ConversationBufferMemory(return_messages = True) # åˆå§‹åŒ– memory
#source_mapping = {} # åŸæœ¬æ˜¯ listï¼Œæ”¹ç”¨ dict ä»¥ uuid ç•¶ Key è¾¨è­˜æ¯ä¸€æ¬¡å›ç­”ï¼Œé¿å…è¨˜æ†¶éºå¤±
app.config["memory"] = CustomMemory() # Flask context-safeï¼Œç¢ºä¿æ¯æ¬¡è®€åŒæ¨£çš„ memory (Flask å¯èƒ½é–‹å•Ÿå¤šåŸ·è¡Œåºï¼Œå› debug = true)
print("ğŸ”¥ Flask å•Ÿå‹•ä¸­ï¼ŒDEBUG =", app.debug)

# ç”¨ä»¥è¼‰å…¥é¦–é 
@app.route("/", methods=["GET"])
def home():
    memory = current_app.config["memory"]
    return render_template("index.html", memory=memory.get_history())

# æ¸…é™¤é‡ç½® Memory
@app.route("/reset", methods=["POST"])
def reset_memory():
    current_app.config["memory"] = CustomMemory()
    return jsonify({"status": "cleared"})

# fetch User ç™¼éä¾†çš„ json
@app.route("/chat", methods=["POST"])
def chat():
    memory = current_app.config["memory"]
    data = request.get_json()
    query = data.get("query", "")
    memory.add_user_message(query)

    # Debug å°å‡ºè¨˜æ†¶å…§å®¹
    print("ç¾åœ¨çš„è¨˜æ†¶å…§å®¹ï¼š")
    for m in memory.get_history():
        print(f"{m['role']}: {m['content']}")

    retrieved_chunks = search_similar_chunks(query, top_k=4) # å¼•ç”¨æ®µè½
    top_chunks = [chunk["text"] for chunk in retrieved_chunks]
    answer = generate_answer(query, top_chunks, history=memory.get_history())
    memory.add_ai_message(answer, sources=retrieved_chunks)

    return jsonify({
        "answer": answer,
        "sources": retrieved_chunks
    })

# def home():
#     answer = ""
#     query = ""
#     retrieved_chunks = []

#     if request.method == "POST":
#         # å–å¾—ä½¿ç”¨è€…è¼¸å…¥çš„å•é¡Œ
#         query = request.form["query"]
#         memory.add_user_message(query) # åŠ å…¥ memory

#         # èªæ„æª¢ç´¢ç›¸é—œæ®µè½
#         retrieved_chunks = search_similar_chunks(query, top_k = 4)
#         top_chunks = [chunk["text"] for chunk in retrieved_chunks]

#         # # æ›´æ–°è¨˜æ†¶é«”ï¼ˆå• + ç•™ç©ºå›ç­”ï¼‰
#         # memory.chat_memory.add_user_message(query)
#         # memory.chat_memory.add_ai_message("(å°šæœªå›ç­”)")

#         #newer version
#         answer = generate_answer(query, top_chunks, history = memory.get_history())
#         msg_id = memory.add_ai_message(answer, sources = retrieved_chunks)
#         # # ä»¥ uuid å„²å­˜ä¸¦å¼•ç”¨æ®µè½
#         # msg_id = str(uuid.uuid4())
#         # memory.chat_memory.messages[-1].metadata = {"id" : msg_id} # åœ¨æœ€å¾Œï¼ˆ[-1]ï¼‰çš„ä½ç½®åŠ ä¸Šidï¼Œæ­¤æ™‚æœ€å¾Œä¸€ç­†æ˜¯ AI_message "å°šæœªå›ç­”"
#         # source_mapping[msg_id] = retrieved_chunks

#         # # å‘¼å« GPT æ¨¡å‹ç”¢ç”Ÿå›ç­”ï¼ˆå…§éƒ¨æœƒçµ„ promptï¼‰
#         # history = memory.chat_memory.messages
#         # answer = generate_answer(query, top_chunks, history = history)
#         # memory.chat_memory.messages[-1].content = answer  # å°‡ GPT å›ç­”å¯«å…¥è¨˜æ†¶é«”

#         query = ""  # æ¸…ç©ºæŸ¥è©¢æ¬„

#     return render_template(
#         "index.html", 
#         query = query, 
#         memory=build_memory(memory),
#         #answer = answer
#     )

if __name__ == "__main__":
    app.run(use_reloader=False)